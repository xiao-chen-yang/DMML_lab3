<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>STATS5099 Data Mining and Machine Learning</title>
  <meta name="description" content="STATS5099 Data Mining and Machine Learning" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="STATS5099 Data Mining and Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="STATS5099 Data Mining and Machine Learning" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  

<link rel="next" href="k-nn-classification-iris-dataset.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="include/webex.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome to DMML Lab 3</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#k-nn"><i class="fa fa-check"></i><b>1.1</b> k-NN</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#linear-and-quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>1.2</b> Linear and quadratic discriminant analysis</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="k-nn-classification-iris-dataset.html"><a href="k-nn-classification-iris-dataset.html"><i class="fa fa-check"></i><b>2</b> k-NN classification: Iris dataset</a>
<ul>
<li class="chapter" data-level="2.1" data-path="k-nn-classification-iris-dataset.html"><a href="k-nn-classification-iris-dataset.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>2.1</b> Exploratory data analysis </a></li>
<li class="chapter" data-level="2.2" data-path="k-nn-classification-iris-dataset.html"><a href="k-nn-classification-iris-dataset.html#classification-using-k-nn"><i class="fa fa-check"></i><b>2.2</b> Classification using k-NN</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="k-nn-classification-iris-dataset.html"><a href="k-nn-classification-iris-dataset.html#data-splitting"><i class="fa fa-check"></i><b>2.2.1</b> Data splitting</a></li>
<li class="chapter" data-level="2.2.2" data-path="k-nn-classification-iris-dataset.html"><a href="k-nn-classification-iris-dataset.html#distances"><i class="fa fa-check"></i><b>2.2.2</b> Distances</a></li>
<li class="chapter" data-level="2.2.3" data-path="k-nn-classification-iris-dataset.html"><a href="k-nn-classification-iris-dataset.html#finding-the-optimal-value-of-k"><i class="fa fa-check"></i><b>2.2.3</b> Finding the optimal value of k</a></li>
<li class="chapter" data-level="2.2.4" data-path="k-nn-classification-iris-dataset.html"><a href="k-nn-classification-iris-dataset.html#prediction"><i class="fa fa-check"></i><b>2.2.4</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="k-nn-classification-iris-dataset.html"><a href="k-nn-classification-iris-dataset.html#task"><i class="fa fa-check"></i><b>2.3</b> Task</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="lda-and-qda-iris-dataset.html"><a href="lda-and-qda-iris-dataset.html"><i class="fa fa-check"></i><b>3</b> LDA and QDA: Iris dataset</a>
<ul>
<li class="chapter" data-level="3.1" data-path="lda-and-qda-iris-dataset.html"><a href="lda-and-qda-iris-dataset.html#checking-assumptions"><i class="fa fa-check"></i><b>3.1</b> Checking assumptions</a></li>
<li class="chapter" data-level="3.2" data-path="lda-and-qda-iris-dataset.html"><a href="lda-and-qda-iris-dataset.html#lda"><i class="fa fa-check"></i><b>3.2</b> LDA</a></li>
<li class="chapter" data-level="3.3" data-path="lda-and-qda-iris-dataset.html"><a href="lda-and-qda-iris-dataset.html#task-1"><i class="fa fa-check"></i><b>3.3</b> Task</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="exercise-haberman.html"><a href="exercise-haberman.html"><i class="fa fa-check"></i><b>4</b> Exercise: Haberman</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STATS5099 Data Mining and Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">STATS5099 Data Mining and Machine Learning</h1>
</div>
<div id="welcome-to-dmml-lab-3" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">1</span> Welcome to DMML Lab 3<a href="index.html#welcome-to-dmml-lab-3" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In week 3, we have studied <span class="math inline">\(k\)</span>-nearest neighbours (<span class="math inline">\(k\)</span>-NN) and linear/quadratic discriminant analysis (LDA/QDA). We also introduced measures to evaluate the performance of classifiers, such as (mis)correct classification rate, class-specific rates, sensitivity and specificity, ROC and AUC, and two data splitting approaches, namely training, validation and test split, and cross-validation.</p>
<p>Before reviewing specific classifiers, let's first summarise the general steps for building and evaluating classifiers.</p>
<p>Suppose we have divided the data into training, validation and test sets. Then, the procedure is as follows.</p>
<ol style="list-style-type: decimal">
<li><p>Build the classifier on the training data.</p></li>
<li><p>Use the classifier built in step 1 to make predictions for data in the validation set and evaluate its performance.</p></li>
</ol>
<p>(Implement steps 1 and 2 for all proposed classifiers and different parameter values in the classifier, e.g. <span class="math inline">\(k\)</span> in <span class="math inline">\(k\)</span>-NN.)</p>
<ol start="3" style="list-style-type: decimal">
<li><p>Select the optimal classifier and its parameters (if any) to be the one with the highest correct classification rate (or some other appropriate evaluation metrics) on the validation set.</p></li>
<li><p>Re-run the selected classifier on the test set to make predictions.</p></li>
</ol>
<p>In the case that the data set is small, <span class="math inline">\(K\)</span>-fold cross-validation may be used instead of training and validation split. This essentially means repeating steps 1 and 2 for <span class="math inline">\(K\)</span> rounds, where in each round, use <span class="math inline">\((K-1)/K\)</span> proportion of data for building the classifier and the remaining <span class="math inline">\(1/K\)</span> proportion of data for evaluating the classifier. The final validation performance is the mean correct classification rate averaged over <span class="math inline">\(K\)</span> rounds. Once the optimal classifier is selected (i.e. step 3), we can proceed to make predictions (i.e. step 4).</p>
<p>The <code>R</code> command for manually splitting the data into training, validation and test sets is given below.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="index.html#cb1-1" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(data) <span class="co">#sample size</span></span>
<span id="cb1-2"><a href="index.html#cb1-2" tabindex="-1"></a>ind1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>n),        <span class="fu">floor</span>(train.prop <span class="sc">*</span> n)) <span class="co">#train.prop stands for the proportion of data in the training set</span></span>
<span id="cb1-3"><a href="index.html#cb1-3" tabindex="-1"></a>ind2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>n)[<span class="sc">-</span>ind1], <span class="fu">floor</span>(valid.prop <span class="sc">*</span> n)) <span class="co">#valid.prop stands for the proportion of data in the validation set</span></span>
<span id="cb1-4"><a href="index.html#cb1-4" tabindex="-1"></a>ind3 <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>n),<span class="fu">c</span>(ind1,ind2))</span>
<span id="cb1-5"><a href="index.html#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="index.html#cb1-6" tabindex="-1"></a>train.data <span class="ot">&lt;-</span> data[ind1, ]</span>
<span id="cb1-7"><a href="index.html#cb1-7" tabindex="-1"></a>valid.data <span class="ot">&lt;-</span> data[ind2, ]</span>
<span id="cb1-8"><a href="index.html#cb1-8" tabindex="-1"></a>test.data  <span class="ot">&lt;-</span> data[ind3, ]</span>
<span id="cb1-9"><a href="index.html#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="index.html#cb1-10" tabindex="-1"></a><span class="co"># Remark: The floor() function is used to round any number to integers.</span></span></code></pre></div>
<p>There are also built-in functions for data splitting in many <code>R</code> packages. For example, in the <code>SDMTune</code> package.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="index.html#cb2-1" tabindex="-1"></a><span class="co"># The following codes are non-examinable.</span></span>
<span id="cb2-2"><a href="index.html#cb2-2" tabindex="-1"></a><span class="fu">library</span>(SDMtune)</span>
<span id="cb2-3"><a href="index.html#cb2-3" tabindex="-1"></a>datasets <span class="ot">&lt;-</span> <span class="fu">trainValTest</span>(data, <span class="at">val =</span> valid.prop, <span class="at">test =</span> test.prop)</span>
<span id="cb2-4"><a href="index.html#cb2-4" tabindex="-1"></a>train.data <span class="ot">&lt;-</span> datasets[[<span class="dv">1</span>]]</span>
<span id="cb2-5"><a href="index.html#cb2-5" tabindex="-1"></a>val.data <span class="ot">&lt;-</span> datasets[[<span class="dv">2</span>]]</span>
<span id="cb2-6"><a href="index.html#cb2-6" tabindex="-1"></a>test.data <span class="ot">&lt;-</span> datasets[[<span class="dv">3</span>]]</span></code></pre></div>
<div id="k-nn" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> k-NN<a href="index.html#k-nn" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose we have training features <code>train.X</code>, training labels <code>train.Y</code>, validation features <code>valid.X</code> and validation labels <code>valid.Y</code>. The <span class="math inline">\(k\)</span>-NN classifier can be built by using</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="index.html#cb3-1" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb3-2"><a href="index.html#cb3-2" tabindex="-1"></a>valid.pred <span class="ot">&lt;-</span> <span class="fu">knn</span>(train.X, valid.X, train.Y, <span class="at">k=</span>k) <span class="co">#k is the number of neighbours considered</span></span></code></pre></div>
<p><code>R</code> also have built-in functions for performing 1-NN and leave-one-out cross-validation of <span class="math inline">\(k\)</span>-NN.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="index.html#cb4-1" tabindex="-1"></a><span class="co"># 1-NN</span></span>
<span id="cb4-2"><a href="index.html#cb4-2" tabindex="-1"></a>valid.pred<span class="fl">.1</span>NN <span class="ot">&lt;-</span> <span class="fu">knn1</span>(train.X, valid.X, train.Y)</span>
<span id="cb4-3"><a href="index.html#cb4-3" tabindex="-1"></a></span>
<span id="cb4-4"><a href="index.html#cb4-4" tabindex="-1"></a><span class="co"># leave-one-out cross-validation of k-NN</span></span>
<span id="cb4-5"><a href="index.html#cb4-5" tabindex="-1"></a>cv <span class="ot">&lt;-</span> <span class="fu">knn.cv</span>(train.X, train.Y, <span class="at">k=</span>k)</span></code></pre></div>
<p>To decide the value of <span class="math inline">\(k\)</span> in <span class="math inline">\(k\)</span>-NN, we will follow steps 1 and 2 as described above. That is, evaluate the performance of <span class="math inline">\(k\)</span>-NN on the validation set or using cross-validation for a range of <span class="math inline">\(k\)</span> and select the optimal <span class="math inline">\(k\)</span> that returns the highest validation correct classification rate.</p>
</div>
<div id="linear-and-quadratic-discriminant-analysis" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Linear and quadratic discriminant analysis<a href="index.html#linear-and-quadratic-discriminant-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Before implementing LDA and QDA, it is important to check if the assumptions are satisfied, i.e. the feature vectors follow multivariate Gaussian distributions, and additionally for LDA, the covariance matrices are equal across classes. In <code>R</code>, two useful commands for checking these assumptions are:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="index.html#cb5-1" tabindex="-1"></a><span class="co"># calculate variance by group</span></span>
<span id="cb5-2"><a href="index.html#cb5-2" tabindex="-1"></a><span class="fu">aggregate</span>(x, <span class="at">by=</span><span class="fu">list</span>(factor), <span class="at">FUN=</span>var) <span class="co">#&#39;x&#39; is a feature vector and &#39;factor&#39; is used to group features; for classification, the class label can be used as &#39;factor&#39;. </span></span>
<span id="cb5-3"><a href="index.html#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="index.html#cb5-4" tabindex="-1"></a><span class="co"># density plots, scatterplot, and Pearson correlation</span></span>
<span id="cb5-5"><a href="index.html#cb5-5" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb5-6"><a href="index.html#cb5-6" tabindex="-1"></a><span class="fu">ggpairs</span>(data, ggplot2<span class="sc">::</span><span class="fu">aes</span>(<span class="at">colour=</span>factor)) <span class="co">#create plots by groups</span></span>
<span id="cb5-7"><a href="index.html#cb5-7" tabindex="-1"></a><span class="co"># You could also add the argument &#39;columns&#39; to specify which columns to be plotted, e.g.</span></span>
<span id="cb5-8"><a href="index.html#cb5-8" tabindex="-1"></a><span class="fu">ggpairs</span>(data, <span class="at">columns=</span><span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>, ggplot2<span class="sc">::</span><span class="fu">aes</span>(<span class="at">colour=</span>factor)) <span class="co">#plotting 2nd and 3rd columns</span></span></code></pre></div>
<p>The syntax for applying LDA and QDA is same as building a regression model:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="index.html#cb6-1" tabindex="-1"></a>LDA <span class="ot">&lt;-</span> <span class="fu">lda</span>(Y <span class="sc">~</span> X1 <span class="sc">+</span> X2 <span class="sc">+</span> X3, data)</span>
<span id="cb6-2"><a href="index.html#cb6-2" tabindex="-1"></a>QDA <span class="ot">&lt;-</span> <span class="fu">qda</span>(Y <span class="sc">~</span> X1 <span class="sc">+</span> X2 <span class="sc">+</span> X3, data)</span></code></pre></div>
<p>By default, the prior probabilities of each class are estimated as the class proportions. It can be specified explicitly by adding the argument <code>prior</code>. For example, assume we have a binary classification problem with equal prior for each class. Then we may change the code to:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="index.html#cb7-1" tabindex="-1"></a>LDA <span class="ot">&lt;-</span> <span class="fu">lda</span>(Y <span class="sc">~</span> X1 <span class="sc">+</span> X2 <span class="sc">+</span> X3, data, <span class="at">prior=</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>))</span></code></pre></div>

</div>
</div>
<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  if (t = document.getElementById("webex-total_correct")) {
    var correct = document.getElementsByClassName("webex-correct").length;
    var solvemes = document.getElementsByClassName("webex-solveme").length;
    var radiogroups = document.getElementsByClassName("webex-radiogroup").length;
    var selects = document.getElementsByClassName("webex-select").length;
    
    t.innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");
  
  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");
  
  var cl = this.classList
  
  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }
  
  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;
  
  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }
  
  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }
  
  update_total_correct();
}

window.onload = function() {
  console.log("onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;
  }
  
  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }
  
  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
  }

  update_total_correct();
}

</script>
            </section>

          </div>
        </div>
      </div>

<a href="k-nn-classification-iris-dataset.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["main.pdf", "main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
